
============================================================
PROMPT: In the context of machine learning, a sparse autoencoder
============================================================
Processing with single SAE hook...
Input shape: torch.Size([1, 12, 4096])
Last token activated features: torch.Size([1, 192])
Output shape: torch.Size([1, 12, 4096])
Processing with double SAE hook (2-hook)...
Input shape: torch.Size([1, 12, 4096])

Last token feature statistics:
Features in first pass: 192
Features in second pass: 192
Shared features: 178
Reactivation ratio: 0.9271 (92.71%)
Jaccard similarity: 0.8641 (86.41%)
Output shape: torch.Size([1, 12, 4096])
Processing with constant SAE hook (converging features)...
Input shape: torch.Size([1, 12, 4096])

Last token position: Starting convergence loop
Iteration 1, Active features: 192
Iteration 2, Jaccard similarity: 0.8641
  Active features: 192
Iteration 3, Jaccard similarity: 0.8462
  Active features: 192
Iteration 4, Jaccard similarity: 0.8824
  Active features: 192
Iteration 5, Jaccard similarity: 0.8641
  Active features: 192
Iteration 6, Jaccard similarity: 0.8551
  Active features: 192
Iteration 7, Jaccard similarity: 0.8373
  Active features: 192
Iteration 8, Jaccard similarity: 0.8113
  Active features: 192
Iteration 9, Jaccard similarity: 0.7615
  Active features: 192
Iteration 10, Jaccard similarity: 0.7696
  Active features: 192
Iteration 11, Jaccard similarity: 0.7696
  Active features: 192
Iteration 12, Jaccard similarity: 0.8199
  Active features: 192
Iteration 13, Jaccard similarity: 0.8824
  Active features: 192
Iteration 14, Jaccard similarity: 0.8916
  Active features: 192
Iteration 15, Jaccard similarity: 0.9592
  Active features: 192
Iteration 16, Jaccard similarity: 0.9492
  Active features: 192
Iteration 17, Jaccard similarity: 0.9492
  Active features: 192
Iteration 18, Jaccard similarity: 0.9794
  Active features: 192
Iteration 19, Jaccard similarity: 0.9394
  Active features: 192
Iteration 20, Jaccard similarity: 0.9896
  Active features: 192
Iteration 21, Jaccard similarity: 0.9794
  Active features: 192
Iteration 22, Jaccard similarity: 0.9794
  Active features: 192
Iteration 23, Jaccard similarity: 0.9692
  Active features: 192
Iteration 24, Jaccard similarity: 0.9692
  Active features: 192
Iteration 25, Jaccard similarity: 0.9692
  Active features: 192
Iteration 26, Jaccard similarity: 0.9794
  Active features: 192
Iteration 27, Jaccard similarity: 0.9592
  Active features: 192
Iteration 28, Jaccard similarity: 0.9592
  Active features: 192
Iteration 29, Jaccard similarity: 0.9794
  Active features: 192
Iteration 30, Jaccard similarity: 0.9692
  Active features: 192
Iteration 31, Jaccard similarity: 0.9896
  Active features: 192
Iteration 32, Jaccard similarity: 0.9794
  Active features: 192
Iteration 33, Jaccard similarity: 0.9692
  Active features: 192
Iteration 34, Jaccard similarity: 0.9896
  Active features: 192
Iteration 35, Jaccard similarity: 0.9896
  Active features: 192
Detected cycle! Indices at iteration 36 match those from iteration 35
Cycle length: 1
First→Final Jaccard similarity: 0.0079
First iteration: 192 features, Final iteration: 192 features
Shared features between first and final: 3

============================================================
PROMPT: In the context of machine learning, a sparse autoencoder
============================================================

NONE HOOK:
Next token: ' is'
Top 5 tokens:
  1. ' is' (prob: 0.9053)
  2. ' (' (prob: 0.0752)
  3. ' [' (prob: 0.0086)
  4. ' aims' (prob: 0.0056)
  5. ',' (prob: 0.0054)

SINGLE HOOK:
Next token: ' is'
Top 5 tokens:
  1. ' is' (prob: 0.8616)
  2. ' (' (prob: 0.1104)
  3. ',' (prob: 0.0125)
  4. ' attempts' (prob: 0.0087)
  5. ' refers' (prob: 0.0067)

DOUBLE HOOK:
Next token: ' is'
Top 5 tokens:
  1. ' is' (prob: 0.8869)
  2. ' (' (prob: 0.0886)
  3. ',' (prob: 0.0118)
  4. ' attempts' (prob: 0.0066)
  5. ' can' (prob: 0.0060)

CONSTANT HOOK:
Next token: '-of'
Top 5 tokens:
  1. '-of' (prob: 0.9990)
  2. '_of' (prob: 0.0005)
  3. ' Of' (prob: 0.0003)
  4. 'Of' (prob: 0.0002)
  5. ' of' (prob: 0.0000)

⚠️ None hook and Constant hook predict different tokens!

⚠️ Single hook and Constant hook predict different tokens!

⚠️ Double hook and Constant hook predict different tokens!

DISTRIBUTION DIFFERENCES (KL DIVERGENCE):
None vs Single hook: 0.037452
None vs Double hook: 0.033436
None vs Constant hook: 28.056669
Single vs Double hook: 0.004710
Single vs Constant hook: 27.802044
Double vs Constant hook: 27.878016
